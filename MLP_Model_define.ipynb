{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version:  2.1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchinfo import summary\n",
    "import tqdm as notebook_tqdm\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print('pytorch version: ', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cpu\n"
     ]
    }
   ],
   "source": [
    "# cpu를 이용할지 gpu를 이용할지 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뒤에서 여러번 사용할 값들을 저장할 변수 +\n",
    "# 모델에 설정할 값(모델자체, 학습할때 필요한 값 등등)으로 성능에 영향을 주는 값들을 저장할 변수 -> hyper parameter \n",
    "\n",
    "BATCH_SIZE = 256   # 모델의 파라미터를 업데이트할 때 사용할 데이터의 개수 (한 번에 몇 개의 데이터를 입력할지를 정의)\n",
    "N_EPOCH = 20   # 전체 train dataset을 한 번 학습한 것을 1epoch\n",
    "LR = 0.001    # 학습률: 파라미터 update할 때 gradient 값에 곱해줄 값 (새로운 parameter를 계산할 때, gradient를 얼마나 반영할지 비율)\n",
    "\n",
    "# step : parameter를 한 번 업데이트하는 단위 (1 step 당 학습데이터수: batch size)\n",
    "# epoch : 전체 학습데이터셋을 한 번 학습한 단위\n",
    "#         1 epoch 당 step 횟수 = ceil(총 데이터 수 / batch size)\n",
    "\n",
    "DATASET_SAVE_PATH = 'datasets'  # 데이터셋을 저장할 디렉토리 경로\n",
    "MODEL_SAVE_PATH = 'models'  # 학습-평가가 끝난 모델을 저장할 디렉토리 경로\n",
    "\n",
    "os.makedirs(DATASET_SAVE_PATH, exist_ok=True)\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T05:02:52.852140Z",
     "start_time": "2021-08-30T05:02:52.563117Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MNIST dataset Loading\n",
    "\n",
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to datasets/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 9912422/9912422 [00:00<00:00, 25337447.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets/MNIST/raw/train-images-idx3-ubyte.gz to datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 28881/28881 [00:00<00:00, 36366164.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets/MNIST/raw/train-labels-idx1-ubyte.gz to datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████| 1648877/1648877 [00:00<00:00, 11530194.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 4542/4542 [00:00<00:00, 7766216.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to datasets/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### MNIST Dataset을 다운로드 + dataset 객체를 생성\n",
    "# tarin dataset\n",
    "## torchvision.datasets\n",
    "train_set = datasets.MNIST(root=DATASET_SAVE_PATH,  # dataset을 저장할 디렉도리 경로\n",
    "                           train=True,  # trainset(훈련용): True, testset(검증용): False\n",
    "                           download=True,  # root에 저장된 데이터파일들이 없을때 다운로드 받을지 여부\n",
    "                           transform=transforms.ToTensor()   # 데이터 전처리\n",
    "                          )\n",
    "# ToTensor(): ndarray, PIL.Image 객체를 torch.Tensor로 변환.\n",
    "#             pixcel값 정규화(normalize) - 0~1 사이의 실수로 변환. \n",
    "test_set = datasets.MNIST(root=DATASET_SAVE_PATH,\n",
    "                          train=False,\n",
    "                          download=True,\n",
    "                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_set)   # Dataset type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: datasets\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: datasets\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 개수 확인\n",
    "print(len(train_set), len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset을 모델에 어떻게 제공할지를 설정 -> 학습/평가시 설정된대로 데이터를 loading\n",
    "# 학습훈련용 Dataloader\n",
    "train_loader = DataLoader(train_set,   # Dataset\n",
    "                          batch_size=BATCH_SIZE,   # batch_size를 설정\n",
    "                          shuffle=True,    # 한 epoch이 끝나면 다음 epoch 전에 데이터를 섞을지 여부를 결정함\n",
    "                          drop_last=True,  # 마지막 batch의 데이터 수가 설정된 batch_size보다 적을 경우 drop(학습에 사용x)할지 여부\n",
    "                         )\n",
    "# 평가용 Dataloader\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch당 step 수\n",
      "trainset:  234\n",
      "testset:  40\n"
     ]
    }
   ],
   "source": [
    "print('1 epoch당 step 수')\n",
    "print('trainset: ', len(train_loader))\n",
    "print('testset: ', len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 네트워크(모델) 정의\n",
    "- Network : 전체 모델 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class로 정의 : nn.Module을 상속해서 만듦\n",
    "class MNistModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        모델 객체 생성시 , 모델구현(정의)에 필요한 것들을 초기화\n",
    "        필요한 것: layer 등등.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        ## 783(pixcel수) -> 128개로 축소\n",
    "        self.lr1 = nn.Linear(28*28, 128)   # input feature의 크기 지정: 784개의 feature를 입력받음, output size: 128\n",
    "        \n",
    "        ## 128 feature -> 64개로 축소\n",
    "        self.lr2 = nn.Linear(128, 64)\n",
    "        \n",
    "        ## 64 feature -> 출력결과 10(각 범주의 확률)\n",
    "        self.lr3 = nn.Linear(64, 10)\n",
    "\n",
    "        ## activation function define (ReLU 사용)\n",
    "        self.relu = nn.ReLU()    # f(x) = max(x,0).  음수는 무조건 0으로 return 된다.\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        input data를 입력받아서 output data를 만들때 까지의 계산 흐름을 정의\n",
    "        ===> foward propagation\n",
    "        parameter\n",
    "            x: input data\n",
    "        return \n",
    "            torch.Tensor: output data(prediction result)\n",
    "        \"\"\"\n",
    "        # init에서 생성한 function들을 이용해서 계산\n",
    "        ## 순서 :  x -> 1차원으로 변환 -> lr1 -> ReLU -> lr2 -> ReLU -> lr3 -> output \n",
    "        x = torch.flatten(x, start_dim=1)  # input(batch_size, channel, height, width) -> (batch_size, 전체pixcel)로 flatten 시키기\n",
    "        \n",
    "        x = self.lr1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.lr2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        output = self.lr3(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.arange(28*28).reshape(1, 1, 28, 28)\n",
    "print(i.shape) # [데이터개수, 채널, height, width]\n",
    "\n",
    "# 데이터 개수는 유지하면서 [1, 784]로 바꾸기. \n",
    "# 다차원 tensor -> 1차원 : flatten([start_dim=axis]) 사용. 지정한 axis부터 합친다\n",
    "torch.flatten(i, start_dim=1).shape  # axis0은 유지하고, axis1부터를 합친다(flatten)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNistModel(\n",
      "  (lr1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (lr2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (lr3): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 정의한 모델 클래스로부터 모덷ㄹ 객체를 생성\n",
    "model = MNistModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MNistModel                               [256, 10]                 --\n",
       "├─Linear: 1-1                            [256, 128]                100,480\n",
       "├─ReLU: 1-2                              [256, 128]                --\n",
       "├─Linear: 1-3                            [256, 64]                 8,256\n",
       "├─ReLU: 1-4                              [256, 64]                 --\n",
       "├─Linear: 1-5                            [256, 10]                 650\n",
       "==========================================================================================\n",
       "Total params: 109,386\n",
       "Trainable params: 109,386\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 28.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.80\n",
       "Forward/backward pass size (MB): 0.41\n",
       "Params size (MB): 0.44\n",
       "Estimated Total Size (MB): 1.65\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model의 연산 흐름 및 정보를 확인 => torchinfo 패키지를 사용\n",
    "torchinfo.summary(model, (256, 1, 28, 28)) # summary(정보를 확인하기위한 모델 객체, input shape; tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# train dataset의 첫 번째 batch를 이용해서 inference 해보자.\n",
    "x_batch, y_batch = next(iter(train_loader))   # train_loader의 첫 번째 반복값을 가져온다. 튜플로 묶어서 가져와서 두 개의 변수로 따로따로 줌.\n",
    "print(x_batch.shape, y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 10])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_batch = model(x_batch)  # model의 forward() 메소드가 실행됨\n",
    "pred_batch.shape  # 지정해준 크기의 output이 나온 것 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2097,  0.1269,  0.0903,  0.0011, -0.0487, -0.0156, -0.0315, -0.0427,\n",
       "         0.1150, -0.1054], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_batch[0]  # 첫 번째 이미지에 대한 추론결과 (class별 확률 도출! 가장 큰 확률의 index를 조회해 보자.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 index가 제일 크니까, 1이미지로 예측한 것\n",
    "pred_batch[0].argmax()   # 1 index가 제일 크니까, 1이미지로 예측한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch[0]   # 정답은 6이미지 이었음 -> 예측이 틀림!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(22)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred_batch의 예측값과 y_batch가 동일한 것의 개수는? (즉, 맞은 개수는?)\n",
    "torch.sum(pred_batch.argmax(dim=1) == y_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "347.844px",
    "left": "1891px",
    "right": "20px",
    "top": "361px",
    "width": "486px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
